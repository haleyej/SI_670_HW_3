{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWTe9VS3_b11"
      },
      "source": [
        "## SI 670 Applied Machine Learning, Week 3: Regularization, Cross Validation, and Logistic Regression\n",
        "\n",
        "For this assignment, you will be exercising on questions related to Logistic regression, Dummy classifiers, and cross-validation.\n",
        "\n",
        "* The coding homework is worth 50 points in total. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
        "\n",
        "* Submit your completed notebook file to the Canvas site - **IMPORTANT**: please name your submitted file `si670f23-hw3-youruniqname.ipynb`\n",
        "\n",
        "* Any file submitted after the deadline will be marked as late. Please consult the syllabus regarding late submission policies. You can submit the homework as many time as you want, but only your latest submission will be graded.\n",
        "\n",
        "* As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates. If you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1 (20 points) Bias and Variance\n",
        "\n",
        "\n",
        "Your task is to investigate the influence of different regularization parameters on the coefficients of a regression model.\n",
        "\n",
        "Given 10 points around the function $y = x^2 + 2x + 1$. You are asked to train a linear regression with degree 6 polynomial features. And run it with different regularization parameters $\\alpha \\in \\{0,0.1,1,10,100\\}$.\n",
        "\n",
        "Plot the polynomials from your regression results corresponding to each regularization parameter in one figure.\n"
      ],
      "metadata": {
        "id": "pT5B_jPuRCFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_1():\n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    x_list = [-10.38446879, -8.38394902, -5.47700112, -5.04337481, -1.50548227, 3.65324449, 2.32253022, 7.14588818, 7.44347003, 9.67771813]\n",
        "    y_list = [ 73.21995367, 56.4250573, 24.15989601, 7.14325154, 3.45955269, 6.68448382, 17.93465674, 44.02585723, 79.55124013, 124.46649205]\n",
        "\n",
        "    # Your code here\n",
        "\n",
        "\n",
        "\n",
        "    # Generate original x values\n",
        "    x_original = np.linspace(-10, 10)\n",
        "\n",
        "    # Generate y values based on the function y = x^2 + 2x + 1\n",
        "    y_original = x_original**2 + 2*x_original + 1\n",
        "\n",
        "    # Plot the original function and the data\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(x_list, y_list, label='Data Points', color='black')\n",
        "\n",
        "    # Plot y = x^2 + 2x + 1\n",
        "    plt.plot(x_original, y_original, label='y = x^2 + 2x + 1', color='red')\n",
        "\n",
        "    # Plot the polynomials from your regression results here\n",
        "\n",
        "\n",
        "\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# answer_1()"
      ],
      "metadata": {
        "id": "bxyfRY5xVzEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then give you a data generator that gives 10 data points around the function $y = x^2 + 2x + 1$ each time.\n",
        "\n",
        "Train a linear regression with degree 6 polynomial features for 1000 times to calculate the bias and variance.\n",
        "\n",
        "Apply different regularization parameters $\\alpha \\in \\{0,0.1,1,10,100\\}$\n",
        "\n",
        "return a tuple containing two lists:\n",
        "\n",
        "The first list should contain the bias values at $x^*=0, y^*=1$ corresponding to each regularization parameter. The second list should contain the variance values at $x^*=0, y^*=1$ corresponding to each regularization parameter.\n",
        "\n",
        "Briefly describe how the bias and variance change when the regularization parameter increases."
      ],
      "metadata": {
        "id": "E1WJjzgglzIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_gen():\n",
        "    # Number of data points\n",
        "    n = 10\n",
        "\n",
        "    # Generate original x values: you can choose the range and number of points\n",
        "    x_original = np.linspace(-10, 10, n)\n",
        "\n",
        "    # Generate y values based on the function y = x^2 + 2x + 1\n",
        "    y_original = x_original**2 + 2*x_original + 1\n",
        "\n",
        "    # Add some noise to x and y values\n",
        "    noise_strength_x = 1.0  # Control the noise strength for x\n",
        "    noise_strength_y = 5.0  # Control the noise strength for y\n",
        "\n",
        "    x_noisy = x_original + noise_strength_x * np.random.randn(n)\n",
        "    y_noisy = y_original + noise_strength_y * np.random.randn(n)\n",
        "\n",
        "    return x_noisy, y_noisy\n",
        "\n",
        "\n",
        "def answer_1_1():\n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "    bias_list = []\n",
        "    variance_list = []\n",
        "\n",
        "    # your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return bias_list, variance_list\n",
        "\n",
        "# answer_1_1()"
      ],
      "metadata": {
        "id": "ZZ4jJOBGm217"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer here.**"
      ],
      "metadata": {
        "id": "toaW8M3k7ZaL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-qaxr4YzrIq"
      },
      "source": [
        "### Question 2 (15 points) Cross-validation for very small datasets.\n",
        "\n",
        "We talked about splitting data in training/validation/test.  However, when you have a very small dataset, one issue is that it leads to really tiny validation/test sets, which leads to unreliable test evaluation scores. For example, if you have a dataset with a total of 60 samples, and hold back 25% as a final test set, you'll get a final test set with 15 samples. In this case, a single evaluation score based on merely 15 samples could be very unreliable and probably not something to be relied on heavily.\n",
        "\n",
        "So to make evaluation more reliable, we discussed how people usually use *cross-validation* to generate *multiple* evaluation scores, each on a different train/test split of the data. That is, you split the train and test set multiple times and then calculate the average of the resulting test scores. This is the approach we'll use to estimate a more reliable final test set score.  We don't want to use these final test sets to also tune our hyperparameters, so we make sure to learn the model and tune the hyperparameters using only the data in the training split.  To do that, we do a second cross-validation *within the training data split* so that we have (i) an outer test set and (ii) a separate in cross-validation that produces several inner *training/validation split's* that's used to pick the best configuration/hyper-parameters.\n",
        "\n",
        "Use an outer cross validation with $k=5$ folds, and an inner cross-validation with $k'=3$ folds.  Report the average of the final test set scores you got across all $k=5$ folds.  \n",
        "\n",
        "To simulate a small dataset scenario, we have provided the code that selects the first 60 samples from the built-in diabetes dataset (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html). We've also given you the variable 'alpha_list', which has the range of ridge regression hyperparameter alphe you should use for tuning.\n",
        "\n",
        "Write the code that implements the above scheme on this subset of the boston dataset. You can split the whole dataset into $k=5$ outer folds (step 1) by using the handy `KFold` function (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). In each outer fold, you can then use another `KFold` to split the training data of the outer fold into $k'=3$ inner folds (step 2). In each inner fold, train a Ridge regression model, and use the validation set to evaluate (step 2a). Then you can find the optimal hyper-parameter alpha value within each outer fold (step 2b). Get the final test set score using this optimal model (step 2c). Repeat for all $k=5$ folds to obtain a set of final test scores. (step 3)\n",
        "\n",
        "Finally, you need to return the mean value of the $k=5$ final test scores. This is your final (more reliable) test set prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gbSD2UWzrIr"
      },
      "outputs": [],
      "source": [
        "def answer_2():\n",
        "    from sklearn.datasets import load_diabetes\n",
        "    from sklearn.linear_model import Ridge\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.model_selection import KFold\n",
        "\n",
        "    X,y = load_diabetes(return_X_y=True)\n",
        "    X=X[:60,:]\n",
        "    y=y[:60]\n",
        "    alpha_list = [0.001,0.01,0.1,1,10]\n",
        "\n",
        "    # Your code here\n",
        "\n",
        "    return mean_test_score\n",
        "\n",
        "# answer_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3 (15 points) Regression to the mean\n",
        "\n",
        "Imagine you are working on a regression problem with three features.\n",
        "\n",
        "You will:\n",
        "\n",
        "1. Generate synthetic data.\n",
        "\n",
        "2. Split data into training, validation, and test sets, with a ratio of 6:2:2\n",
        "\n",
        "3. Train two different linear regression models (one with Ridge regularization term with $\\alpha = 0.2$ and the other without).\n",
        "\n",
        "4. Evaluate both models on the validation data with Mean Squared Error.\n",
        "\n",
        "5. Suppose that for each time you will apply the \"better\" model according to the MSE on the validation data, evaluate it on the test data.\n",
        "\n",
        "Repeat this 1000 times.  Each time calculate the average of the error of the \"better\" model on validation data and test data respectively (so you will only record the error of the better model on the validation data, and the error of this same model on the test data.\n",
        "\n",
        "Which average error is smaller? Why do you expect this (or not expect this)?"
      ],
      "metadata": {
        "id": "w_Entr27DLua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def answer_3():\n",
        "\n",
        "    for _ in range(1000):\n",
        "\n",
        "        # Generate synthetic data\n",
        "        X = 2 * np.random.rand(50, 6)  # 50 samples, 6 features\n",
        "        y = 10 + np.dot(X, np.array([3, 5, 2, 0, 0, 0])) + 2 * np.random.randn(50)\n",
        "\n",
        "        # Your code here\n",
        "        # Split data into training, validation, and test sets, with a ratio of 6:2:2\n",
        "\n",
        "\n",
        "\n",
        "        # Train two models\n",
        "        # Model 1: Linear Regression\n",
        "\n",
        "\n",
        "        # Model 2: Ridge Regression with alpha = 0.2\n",
        "\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_mse1 = 0\n",
        "        val_mse2 = 0\n",
        "\n",
        "        print(f\"Validation MSE for Linear Regression: {val_mse1}\")\n",
        "        print(f\"Validation MSE for Ridge Regression: {val_mse2}\")\n",
        "\n",
        "        # Choose the \"better\" model based on validation MSE\n",
        "\n",
        "\n",
        "\n",
        "        # Evaluate 'better' model on the test set\n",
        "        test_mse = 0\n",
        "\n",
        "        print(f\"Test MSE for the 'better' model: {test_mse}\")\n",
        "\n",
        "\n",
        "# answer_3()"
      ],
      "metadata": {
        "id": "MtOfZ-mvrGp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Describe* what happens in the above process, and why does it happens.\n",
        "\n",
        "**Your answer here:**"
      ],
      "metadata": {
        "id": "WMgpyU8fG8st"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}